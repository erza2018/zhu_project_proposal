## Ethicality in Personal Assistant Response Accuracy

# The Project

In the past decade, personal assistants have become more and more prevalent in our daily lives. Assistants such as Siri, Cortana, and Google Assistant have become intimately connected to our day to day by embedding themselves in our phones, laptops, homes, and cars. For this project, I want to conduct an ethical exploration on whether personal assistance are biased towards certain demographics. Are these assistants more or less accurate at understanding specific subsets of the population based on the gender or dialect of the speaker?

# Goals

- Learn about how personal assistants such as Siri and Alexa are trained
- Explore the ethics of these personal assistants' training process
- Conduct our own ethical and efficient data collection
- If there is an ethical bias encountered, how can companies creating personal assistants try and counteract the bias?


# Lingering Questions
- How will we get data? Will we collect our own or will we use existing data sets. If the goal of the research is to explore whether demographic factorrs affect response accuracy, what information do existing data sets include about their research participants?
- How will accuracy be defined?



You can use the [editor on GitHub](https://github.com/erza2018/zhu_project_proposal/edit/gh-pages/index.md) to maintain and preview the content for your website in Markdown files.




